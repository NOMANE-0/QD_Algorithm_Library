# RM_Vision

RM_Vision是一套为robomaster比赛提供自动瞄准装甲板和能量机关的项目。该项目基于中南大学fyt战队2024赛季开源[FYT2024_vision](https://github.com/CSU-FYT-Vision/FYT2024_vision)

## 项目结构

### 项目框架

本项目使用ros2作为通信架构。ros2使用DDS通信，能够将功能模块化并通过网络在局域网内进行模块间的相互通信，且自动支持多线程功能，能够充分利用CPU的性能。

### 项目树

```txt
.
├── rm_auto_aim (自瞄算法)
|
├── rm_auto_record (自动录包)
|
├── rm_bringup (启动及参数文件)
|
├── rm_hardware_driver
|   |
│   ├── hik-camera (海康相机驱动)
|   |
│   └── rm_serial_driver (串口驱动)
|
├── rm_interfaces (自定义msg、srv)
|
├── rm_robot_description (机器人urdf文件，坐标系的定义)
|
├── rm_rune (打符算法)
|
├── rm_upstart (自启动配置)
|
└── rm_utils (工具包) 
    |
    ├── logger (日志库)
    |
    └── math (包括PnP解算、弹道补偿等)
```

## 节点

### armor_detector

装甲板识别节点，处理相机节点的图像，算出装甲板角点和三维位置

### armor_solver

装甲板数据处理节点，根据识别到的装甲板确定跟踪目标，预测下一刻装甲板位置，计算弹道算出ypd发给串口

#### ArmorSolverNode

装甲板处理节点

订阅识别节点得到装甲板信息，然后进行坐标变换到`odom`，调用函数更新预测计算装甲板。同时会发布装甲板的可视化`Markers`

- 初始化，该类对成员都进行初始化操作
- 回调函数，该类有`armorsCallback`和`timerCallback`两个独立函数，分别进行更新EKF模型和计算装甲板位置发送给串口

- `armorsCallback`根据跟踪器`Tracker`状态来执行操作，大体分成第一次识别`init`，否则进行滤波器状态更新，更新完判断是否跟丢再做判断
- `setModeCallback`用来接收串口发来的是否允许自瞄的控制指令
- `timerCallback`以一定频率固定发送云台控制指令，使数据连续

#### Tracker

该类用于对装甲板进行筛选，然后初始化或更新EKF，最后进行跟踪器更新

##### 外部调用

```c++
//构造，tracking_thres和EKF模型需单独初始化
Tracker(double max_match_distance, double max_match_yaw);

//初始化
void init(const Armors::SharedPtr &armors_msg) noexcept;

//更新
void update(const Armors::SharedPtr &armors_msg) noexcept;
```

##### 跟踪器

跟踪器共有四个状态：

- `DETECTING` ：短暂识别到目标，需要更多帧识别信息才能进入跟踪状态（该状态不会控制云台）
- `TRACKING` ：跟踪器正常跟踪目标中（开始跟踪自瞄）
- `TEMP_LOST` ：跟踪器短暂丢失目标，通过卡尔曼滤波器预测目标
- `LOST` ：跟踪器完全丢失目标

#### Solver

给类用于弹道计算，根据EKF预测的数据计算装甲板数据，然后判断要击打的装甲板来计算弹道

##### 外部调用

```c++
//构造,需要依托在节点类里
solveYawPnP_ = std::make_unique<solveYawPnP>(weak_from_this());

//计算弹道
rm_interfaces::msg::GimbalCmd Solver::solve(const rm_interfaces::msg::Target &target,
                                            const rclcpp::Time &current_time,
                                            std::shared_ptr<tf2_ros::Buffer> tf2_buffer_)
```

##### 火控

在要到达给定yaw、pitch前给出开火指令。自瞄会一直发送ywa、pitch，直到枪管刚好在此时的火控范围就发出开火指令

![火控逻辑](images/技术文档-image.png)

##### 弹道模型

在打击装甲板中，yaw一般是准的，而pitch则会收到重力、空气阻力等的影响，弹道并不完全是一条直线，为此需要补偿pitch

- 理想重力模型

g是重力加速度

$$
t =x/v_x \\
y=v_yt+\frac{1}{2} gt^{2}
$$

代码实现

```c++
double IdealCompensator::calculateTrajectory(const double x, const double angle) const noexcept {
  double t = x / (velocity * cos(angle));
  double y = velocity * sin(angle) * t - 0.5 * gravity * t * t;
  return y;
}
```

该方法需要迭代角度`angle`直到y与真实的z(目标与枪管的高度)逼近

- 空气阻力模型

r是空气阻力系数，g是重力加速度
$$
r = \begin{cases}
1 \times 10^{-4} &  \mathit{resistance} < 1 \times 10^{-4} \\
\mathit{resistance} & \text{otherwise}
\end{cases}
\\
t = \frac{e^{r x} - 1}{r \cdot v_x}  \\

y = v_y\cdot t - \frac{1}{2} g t^2
$$

#### SloveYawPnp

该类用于优化装甲板的YAW值。通过假定YAW值，然后将假定的装甲板从装甲板坐标系重投影回像素坐标系，与像素坐标系下的真装甲板做差，差越小则代表假定的YAW越接近真实YAW值

##### 外部调用

```c++
//构造，需依托于节点类
solveYawPnP_ = std::make_unique<solveYawPnP>(weak_from_this());

//调用，会修改 armors_msg 里装甲板 armor.pose.orientation 的yaw
bool solveYawPnP::SloveYawPnp(const rm_interfaces::msg::Armors::SharedPtr armors_msg, const double& predict_yaw, std::shared_ptr<tf2_ros::Buffer> tf2_buffer)

```

##### 三分法

做差求出的YAW在区间$(-\pi/2 ,\pi/2)$上呈下凸函数，存在一个唯一的极小值，三分法便是用来求极小值的。做差得出的值我们这里称之为`cost`。为了不让三分法持续太久，还需要限制迭代次数，或者迭代到一定精度停止迭代

代码实现

```C++
double solveYawPnP::getYaw_stju(double left, double right, int times)
{

    for (int i = 0; i < times; ++i) {

        double mid1 = left + (right - left) / 3;
        double mid2 = right - (right - left) / 3;

        double f1 = getCost_stju(mid1);
        double f2 = getCost_stju(mid2);

        if (f1 < f2) {
            right = mid2;
        } else {
            left = mid1;
        }

    }
    return (left + right) / 2.;

}
```

<video src="images/三分法可视化.mp4"></video>

##### 做差实现

做差分成像素做差和角度做差两部分。

- 像素$pixel$

    $（角点与角点间的距离+线段的差）/重投影线段$ 。yaw越接近，差值越小，分子越小，cost越小
   ![pixel_cost](images/pixel.jpg)

- 角度$angular$

    $重投影线段*两线段夹角/重投影线段$ 。夹角使用的弧度制。yaw越接近，两线段越重合，夹角越小，cost越小
    ![alt text](images/angle.jpg)

在算出两个cost后，还要进行权重划分，当yaw越接近0时应该越相信$pixel$，yaw越大时越相信$angular$。这里可以使用三角函数（$sin(\theta ),cos(\theta )$）来实现，$\theta$在一开始可以使用$\pi$/4使权重相同，后面使用预测的yaw输入

代码实现

```c++
/**
@brief: 计算重投影误差,适用于单板
@param: refs 重投影点
@param: pts 原装甲板像素点
*/
double solveYawPnP::getCost_stju(const std::vector<Eigen::Vector2d> &refs, const std::vector<Eigen::Vector2d> &pts)
{
    std::size_t size = refs.size();

    double cost = 0.;
    for (std::size_t i = 0u; i < size; ++i) {
        std::size_t p = (i + 1u) % size;
        // i - p 构成线段。过程：先移动起点，再补长度，再旋转
        Eigen::Vector2d ref_d = refs[p] - refs[i]; //线段
        Eigen::Vector2d pt_d = pts[p] - pts[i];
        // 长度差代价 + 起点差代价(1 / 2)（0 度左右应该抛弃)
        double pixel_dis = // dis 是指方差平面内到原点的距离
            (0.5 * ((refs[i] - pts[i]).norm() + (refs[p] - pts[p]).norm())
             + std::fabs(ref_d.norm() - pt_d.norm()))
            / ref_d.norm();//像素长度代价
        double angular_dis = ref_d.norm() * get_abs_angle(ref_d, pt_d) / ref_d.norm();//夹角
        // 平方可能是为了配合 sin 和 cos
        // 弧度差代价（0 度左右占比应该大）
        double cost_i;
        
        cost_i = sq(pixel_dis * std::sin(z_to_v_exp))
                + sq(angular_dis * std::cos(z_to_v_exp)) * DETECTOR_ERROR_PIXEL_BY_SLOPE;
        
        
        // 重投影像素误差越大，越相信斜率
        cost += std::sqrt(cost_i);
    }
    return cost;
}
```

#### ExtendedKalmanFilter

扩展卡尔曼（EKF）是`armor_slover`的核心，用于状态预测。

##### 外部调用

- EKF为了通用性采用模板封装，在使用前需确定数据类型。分别为确定观测方程和状态方程。

```c++
// X_N: state dimension, Z_N: measurement dimension
constexpr int X_N = 9, Z_N = 4;

//状态方程
struct Predict {
  explicit Predict(double dt)
  : dt(dt) {}

  template <typename T>
  void operator()(const T x0[X_N], T x1[X_N]) {
    for (int i = 0; i < X_N; i++) {
      x1[i] = x0[i];
    }


    x1[0] += x0[1] * dt;    // v_xyz
    x1[2] += x0[3] * dt;    // linear velocity
    x1[4] += x0[5] * dt;
    x1[6] += x0[7] * dt;    // v_yaw    angular velocity

  }

  double dt;
};

//观测方程
struct Measure {
  template <typename T>
  void operator()(const T x[Z_N], T z[Z_N]) {
    z[0] = x[0] - ceres::cos(x[6]) * x[8];
    z[1] = x[2] - ceres::sin(x[6]) * x[8];
    z[2] = x[4] + x[9];
    z[3] = x[6];
  }
};

using RobotStateEKF = ExtendedKalmanFilter<X_N, Z_N, Predict, Measure>;
```

- 构造EKF，这里的 f 和 h 分别是上述的状态方程和观测方程类；u_q 和 u_r 则是过程噪声协方差矩阵和测量噪声协方差矩阵的更新函数；P0是一个单位矩阵

```c++
    auto u_q = [this]() {
        Eigen::Matrix<double, X_N, X_N> q;
        double t = dt_, x = s2qx_, y = s2qy_, z = s2qz_, yaw = s2qyaw_, r = s2qr_, d_zc=s2qd_zc_;
        double q_x_x = pow(t, 4) / 4 * x, q_x_vx = pow(t, 3) / 2 * x, q_vx_vx = pow(t, 2) * x;
        double q_y_y = pow(t, 4) / 4 * y, q_y_vy = pow(t, 3) / 2 * y, q_vy_vy = pow(t, 2) * y;
        double q_z_z = pow(t, 4) / 4 * x, q_z_vz = pow(t, 3) / 2 * x, q_vz_vz = pow(t, 2) * z;
        double q_yaw_yaw = pow(t, 4) / 4 * yaw, q_yaw_vyaw = pow(t, 3) / 2 * x,
            q_vyaw_vyaw = pow(t, 2) * yaw;
        double q_r = pow(t, 4) / 4 * r;
        double q_d_zc = pow(t, 4) / 4 * d_zc;
        // clang-format off
        //    xc      v_xc    yc      v_yc    zc      v_zc    yaw         v_yaw       r      
        q <<  q_x_x,  q_x_vx, 0,      0,      0,      0,      0,          0,          0,     
            q_x_vx, q_vx_vx,0,      0,      0,      0,      0,          0,          0,   
            0,      0,      q_y_y,  q_y_vy, 0,      0,      0,          0,          0,      
            0,      0,      q_y_vy, q_vy_vy,0,      0,      0,          0,          0,      
            0,      0,      0,      0,      q_z_z,  q_z_vz, 0,          0,          0,      
            0,      0,      0,      0,      q_z_vz, q_vz_vz,0,          0,          0,      
            0,      0,      0,      0,      0,      0,      q_yaw_yaw,  q_yaw_vyaw, 0,      
            0,      0,      0,      0,      0,      0,      q_yaw_vyaw, q_vyaw_vyaw,0,      
            0,      0,      0,      0,      0,      0,      0,          0,          q_r,    
            0,      0,      0,      0,      0,      0,      0,          0,          0;

        // clang-format on
        return q;
    };

    auto u_r = [this](const Eigen::Matrix<double, Z_N, 1> &z) {
        Eigen::Matrix<double, Z_N, Z_N> r;
        // clang-format off
        r << r_x_ * std::abs(z[0]), 0, 0, 0,
            0, r_y_ * std::abs(z[1]), 0, 0,
            0, 0, r_z_ * std::abs(z[2]), 0,
            0, 0, 0, r_yaw_;
        // clang-format on
        return r;
    };

    Eigen::DiagonalMatrix<double, X_N> P0;

    explicit ExtendedKalmanFilter(const PredicFunc &f,
                                const MeasureFunc &h,
                                const UpdateQFunc &u_q,
                                const UpdateRFunc &u_r,
                                const MatrixXX &P0)
```

- 初始化EKF,输入观测数据

``` c++
void ExtendedKalmanFilter::setState(const Eigen::Matrix<double, N_X, 1> &x0)
```

- 更新EKF，更新和预测要一起完成

```c++
//预测，返回预测的状态数据
Eigen::Matrix<double, N_X, 1> ExtendedKalmanFilter::predict()

//更新，输入观测值，返回更新后的状态数据
Eigen::Matrix<double, N_X, 1> update(const Eigen::Matrix<double, N_Z, 1> &z)
```

#### 核心公式

预测：

$$ x_{k|k-1} = F * x_{k-1|k-1} $$

$$ P_{k|k-1} = F * P_{k-1|k-1}* F^T + Q $$

更新:

$$ K = P_{k|k-1} * H^T * (H * P_{k|k-1} * H^T + R)^{-1} $$

$$ x_{k|k} = x_{k|k-1} + K * (z_k - H * x_{k|k-1}) $$

$$ P_{k|k} = (I - K * H) * P_{k|k-1} $$

### hik-camera

海康相机驱动节点

### rm_serial_driver

串口驱动节点

### rune_detector

### rune_solver
